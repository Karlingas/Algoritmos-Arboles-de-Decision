{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<h2><font size=6>Práctica 1</font></h2>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font size=7>Árboles de decisión</font></h1>\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: right\">\n",
    "<font size=4>Alberto Pérez Álvarez (alberto.perez25@alu.uclm.es)</font><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"#ffd433\" size=5>Estudiantes: </font>** \n",
    "\n",
    "* Alberto Pérez Álvarez\n",
    "* Diego García Díaz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Introducción\n",
    "\n",
    "El objetivo de esta práctica es estudiar el uso de árboles de decisión para la predicción del ingreso de distintas personas en función de sus datos censales. Para ello usaremos la base de datos [`adult`](https://archive.ics.uci.edu/dataset/2/adult), también conocida como [`census-income`](https://archive.ics.uci.edu/dataset/20/census+income). \n",
    "\n",
    "En esta práctica comenzaremos explorando `scikit-learn` y su implementación de los árboles de decisión, realizando un estudio comparativo de los distintos hiperparámetros que ofrece. \n",
    "\n",
    "Posteriormente, se proporciona el esqueleto para la implementación del algoritmo C4.5 que usaremos como base para el resto de la práctica. A partir de ella, se pide:\n",
    "- Capacidad de tratar con variables y discretas continuas.\n",
    "- Implementar el error de clasificación, el índice GINI y la entropía condicional para el cálculo del error.\n",
    "- Poda del árbol.\n",
    "- Estudio del algoritmo implementado.\n",
    "\n",
    "Baremo de puntuaciones:\n",
    "\n",
    "| Tarea                     | Peso | \n",
    "|----------|----------|\n",
    "| Estudio comparativo con `scikit-learn`      | 10%   |\n",
    "| Variables discretas       | 15%   |\n",
    "| Variables continuas       | 25%   |\n",
    "| Implementación de las métricas           | 10%   |\n",
    "| Poda del árbol            | 25%   |\n",
    "| Estudio final del algoritmo implementado           | 15%   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Carga del dataset\n",
    "\n",
    "El dataset que usaremos trata de predecir si los ingresos son superiores o inferiores a 50K en base a una serie de variables. Para cargar los datos usaremos `pandas`, mientras que `numpy` será necesario para realizar diversas funciones a lo largo de la práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3.11 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('adult.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Análisis exploratorio\n",
    "\n",
    "Podemos ver información de las distintas variables con `df.info()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, vemos como efectivamente tenemos tanto variables categóricas como numéricas. En principio parece estar todo correcto, sin valores perdidos, pero si observamos los valores únicos de cada variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda col: col.sort_values().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver cómo en `workclass`, `occupation` y `native-country` hay valores desconocidos representados por `?`. Vamos a ver cómo quedaría nuestro DataFrame si los reemplazamos por `NaN` para que `pandas` los reconozca como valores perdidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('?', np.nan).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, ahora podemos ver cómo la cuenta de valores no nulos ha cambiado. Por defecto, como las variables eran categóricas, estaba contando las `?` como una categoría más. \n",
    "\n",
    "Cuando conocemos la causa de los valores perdidos puede tener sentido dejarlos como una categoría más. Por ejemplo, suponed que estamos recogiendo datos de un radar en el que la velocidad máxima que puede medir son 200 km/h. Si un coche pasa a 215 km/h el radar nos daría un `?` en ese dato, pero si sabemos el motivo de estos valores perdidos, podríamos cambiar el nombre de esa categoría a `>200km/h`.\n",
    "\n",
    "Ya que en esta práctica no vamos a introducir el manejo de los valores perdidos en nuestros árboles de decisión, y puesto que dichos valores solo aparecen en variables categóricas, por simplicidad vamos a dejar la base de datos tal cual está, contando a `?` como un valor categórico más. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. De `pandas` a `numpy`\n",
    "\n",
    "A continuación vamos a transformar nuestros datos en arrays de `numpy` ya que los necesitaremos para trabajar con ellos posteriormente. `pandas` tiene muchas características muy útiles para hacer el análisis exploratorio y el preprocesamiento de los datos gracias a sus funciones de selección, agregación, agrupación... pero posteriormente todos los algoritmos de aprendizaje automático suelen trabajar con arrays de `numpy` dada su velocidad.\n",
    "\n",
    "Vamos a empezar con los nombres de las variables. Por un lado vamos a guardar cuáles son nuestras variables predictoras y cuál nuestra variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = features[:-1]\n",
    "target = features[-1]\n",
    "\n",
    "print('Predictoras:',attributes)\n",
    "print('Objetivo:',target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, vamos a distinguir entre variables continuas (las que son de tipo `int64`) y discretas (de tipo `object`), ya que a la hora de hacer nuestros árboles de decisión habrá que tratarlas de forma distinta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_atts = df.columns[df.dtypes == 'int64']\n",
    "\n",
    "disc_atts = df.columns[df.dtypes == 'object'] \n",
    "disc_atts = disc_atts.drop(target)\n",
    "\n",
    "print('Continuas:',cont_atts)\n",
    "print('Discretas:',disc_atts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, separamos el dataset en predictor y objetivo. Es convención en ciencia de datos usar $X$ para las variables predictoras e $y$ para la variable objetivo. La mayoría de los modelos se entrenan usando esas dos variables por separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df[attributes].to_numpy(), df[target].to_numpy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Datos de test\n",
    "\n",
    "Cuando nos enfrentamos a un problema de aprendizaje automático, es imprescindible que los datos de test que usemos para medir el rendimiento del modelo sean distintos a los datos con los que se entrena. En este caso, como los autores del conjunto de datos nos proporcionan un conjunto de datos separado para test, lo usaremos directamente. Si no, tendríamos que dividir el conjunto de datos original en dos partes, una para entrenar y otra para test.\n",
    "\n",
    "**Nota:** En la práctica, es común dividir el conjunto de datos en tres partes: entrenamiento, validación y test. La validación se usa para ajustar los hiperparámetros del modelo, y el conjunto de test se usa para medir el rendimiento final del modelo. En este caso, como no vamos a ajustar hiperparámetros y por simplicidad, no usaremos conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('adult_test.csv')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = df_test[attributes].to_numpy(), df_test[target].to_numpy()\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Árboles de decisión en `scikit-learn`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta práctica vamos a utilizar el módulo [tree](http://scikit-learn.org/stable/modules/tree.html) de `scikit-learn`. Esta librería permite utilizar diversos algoritmos de _machine learning_ en Python, siendo los árboles de decisión uno de ellos. En particular, utilizaremos [`DecisionTreeClassifier`](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html), la implementación de un árbol de decisión para problemas de clasificación de `scikit-learn`. \n",
    "\n",
    "La implementación que tiene `scikit-learn` de los árboles de decisión no es exactamente la del C4.5 si no que el algoritmo se llama CART. Existen algunas diferencias, pero la que más nos afectará es que los árboles generados son **binarios** y que no puede tratar variables discretas sin un procesado previo. \n",
    "\n",
    "Por tanto, para poder usar este algoritmo con nuestros datos tendremos que convertir las variables categóricas a numéricas. Para ello, podríamos usar el método [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) de `scikit-learn`, pero usaremos el método `df.get_dummies()` que nos proporciona directamente `pandas` ya que es similar y más simple de aplicar. Este método básicamente crea una nueva columna por cada valor posible de cada variable categórica y pone un 1 en la columna correspondiente al valor de la fila y un 0 en las demás, pasando así de variables categóricas a numéricas:\n",
    "\n",
    "![OneHotEnconding](./imagenes/get_dummies.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Transformación de los datos para usarlos con `DecisionTreeClassifier`\n",
    "\n",
    "Vamos a transformar nuestros datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe = pd.get_dummies(df.drop(target, axis=1))\n",
    "df_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_ohe = pd.get_dummies(df_test.drop(target, axis=1))\n",
    "df_test_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_ohe.columns) - set(df_test_ohe.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como en el test nos falta una columna (ya que `Holand-Netherlands` no aparece en la variable `native-country`), tenemos que añadirla para no tener problemas posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe, df_test_ohe = df_ohe.align(df_test_ohe, join='outer', axis=1, fill_value=0)\n",
    "df_test_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ohe, X_test_ohe = df_ohe.to_numpy(), df_test_ohe.to_numpy()\n",
    "X_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Estudio de `DecisionTreeClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El `DecisionTreeClassifier` cuenta con una serie de hiperparámetros con los que podemos ajustar su funcionamiento. Algunos de los que nos pueden ser más útiles son:\n",
    "* `criterion`: Especifica la función para medir la calidad de una partición. Puede ser `gini` o `entropy`.\n",
    "* `max_depth`: Profundidad máxima del árbol. \n",
    "* `min_samples_leaf`: Mínimo número de ejemplos que debe haber en una hoja.\n",
    "\n",
    "En la documentación de `scikit-learn` está toda la información sobre los hiperparámetros del algoritmo. Por lo que si se desea se puede extender el estudio probando más configuraciones. Para ello se debe especificar que hiperparámetros extra se han seleccionado, para que sirven y como afectan al árbol y justificar dicho comportamiento con los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree \n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = 'entropy'\n",
    "max_depth = 2\n",
    "min_samples_leaf = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente crea un objeto `DecisionTreeClassifier` especificando los parámetros anteriores, y genera el arbol a partir de los datos con el método `fit(X,y)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol = DecisionTreeClassifier(criterion = criterion,\n",
    "                               max_depth = max_depth,\n",
    "                               min_samples_leaf = min_samples_leaf)\n",
    "arbol.fit(X_ohe,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El árbol se puede visualizar mediante la función `plot_tree()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (12,5)\n",
    "\n",
    "_ = tree.plot_tree(arbol, filled=True, rounded=True, fontsize=10, feature_names=df_ohe.columns, class_names=arbol.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos ver el porcentaje de aciertos o *accuracy* obtenido con el árbol tanto en el conjunto de entrenamiento como en el de test mediante el método `score()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy train:\\t', arbol.score(X_ohe,y))\n",
    "print('Accuracy test: \\t', arbol.score(X_test_ohe,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como el árbol que hemos creado está muy limitado a solo dos niveles de profundidad, el rendimiento del algoritmo en los datos de test es igual o incluso superior al que obtiene al intentar predecir directamente los mismos datos de entrenamiento con los que ha sido entrenado. Para comparar, vamos a crear un árbol por defecto (sin limitar):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol2 = DecisionTreeClassifier()\n",
    "arbol2.fit(X_ohe,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vemos la puntuación que obtiene, al no estar limitado, sobreajusta al máximo a los datos de entrenamiento (se los está aprendiendo de memoria). Esto hace que luego en el conjunto de test obtenga un resultado mucho peor, incluso peor al del árbol básico de 2 niveles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy train:\\t', arbol2.score(X_ohe,y))\n",
    "print('Accuracy test: \\t', arbol2.score(X_test_ohe,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** Este árbol no lo dibujamos porque al ser tan grande, tarda una eternidad y no se ve nada. El árbol limitado tenía 7 nodos, este tiene 9343:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Número de nodos limitado:', arbol.tree_.node_count)\n",
    "print('Número de nodos hoja limitado:', arbol.tree_.n_leaves)\n",
    "\n",
    "print('\\nNúmero de nodos:', arbol2.tree_.node_count)\n",
    "print('Número de nodos hoja:', arbol2.tree_.n_leaves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<font color=\"#B30033\" size=6>TAREA: </font>** Estudio de diferentes configuraciones\n",
    "\n",
    "Debes llevar a cabo un estudio donde debes variar los hiperparámetros del árbol para obtener un buen clasificador. Además, como mínimo se debe mostrar información sobre el `score` obtenido tanto con los datos de entrenamiento como de test, el número de nodos del árbol y la cantidad de nodos hoja del mismo. \n",
    "\n",
    "Después responde a las siguientes preguntas:\n",
    "* ¿Qué efecto observas con la variación de cada uno de los parámetros?\n",
    "* ¿Qué configuración escogerías para obtener un buen clasificador? Justifica tu respuesta.\n",
    "\n",
    "Consejos:\n",
    "* Fíjate en los parámetros por defecto del algoritmo y en la explicación proporcionada para ajustar correctamente los valores. \n",
    "* Los datos están desbalanceados (hay muchos más casos para el valor de la clase `<=50K` que para `>50K`, como se puede ver en la primera de las gráficas de abajo). En este caso, si predecimos siempre `<=50K` obtenemos un 0.7592 de accuracy, cuando está claro que es una predicción muy mala. Por ello, puede ser interesante utilizar además otras métricas como por ejemplo F-score ([`f1_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) en `scikit-learn`) que tengan en cuenta los valores de *precision* and *recall*. \n",
    "* Se recomienda también mostrar información en forma de gráficas, ya pueden ser en el propio Python o incluso con Excel. En Python, una de las opciones más sencillas es usar la librería `seaborn`. A continuación se dejan una serie de ejemplos de gráficas usando `seaborn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Métricas accuracy y F1 cuando se predice siempre la clase mayoritaria\n",
    "print('Zero-R accuracy: ', accuracy_score(y == '>50K', np.repeat(0, len(y))))\n",
    "print('Zero-R F-score: ', f1_score(y == '>50K', np.repeat(0, len(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "# Número de valores para cada clase (categórica)\n",
    "g = sns.countplot(df, x=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relación entre la edad (numérica) y las horas de trabajo por semana (numérica), diferenciando por clase\n",
    "g = sns.lineplot(df, x='age', y='hours-per-week', hue='income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relación entre el nivel de educación (numérica) y las horas de trabajo por semana (numérica), diferenciando por clase y eliminando los intervalos de confianza\n",
    "g = sns.lineplot(df, x='education-num', y='hours-per-week', hue='income', errorbar=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relación entre el tipo de trabajo (categórica) y las horas de trabajo por semana (numérica), diferenciando por clase\n",
    "g = sns.barplot(df, x='workclass', y='hours-per-week', hue='income')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# 4. Implementación de un árbol de clasificación\n",
    "\n",
    "En este apartado, vamos a implementar un árbol de clasificación C4.5. Se proporciona un modelo básico capaz de tratar variables categóricas, realizando las divisiones por error simple, y sin poda. Hay que ampliar el modelo para que cuente con las siguientes características:\n",
    "1. Utilizar el índice GINI para el cálculo del error.\n",
    "2. Utilizar la entropía condicional para el cálculo del error.\n",
    "3. Utilizar variables continuas en el entrenamiento y predicción.\n",
    "4. Poda del árbol.\n",
    "\n",
    "Para la estructura del código vamos a seguir la de los algoritmos de `scikit-learn`. Por tanto, nuestro modelo `C45Classifier` heredará de [`BaseEstimator`](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html), la clase base para todos los estimadores de `scikit-learn`, y de [`ClassifierMixin`](https://scikit-learn.org/stable/modules/generated/sklearn.base.ClassifierMixin.html), la clase base de los clasificadores. Además, debemos implementar los siguientes métodos principales: \n",
    "\n",
    "- `__init__()`: Constructor del modelo, recibirá los hiperparámetros necesarios.\n",
    "- `fit(X,y)`: Método de entrenamiento del modelo. Recibe $X$ e $y$ y devuelve el modelo ya entrenado.\n",
    "- `predict(X)`: Método de predicción del modelo. Recibe $X$ como un conjunto de instancias a predecir y devuelve $y_{pred}$, un vector de predicciones asociadas a $X$.\n",
    "\n",
    "Por otro lado, está el siguiente método que, si bien es importante, al heredar de `ClassifierMixin` ya viene establecido por defecto a `accuracy_score`:\n",
    "- `score(X,y)`: Método de evaluación del modelo. Recibe $X$ e $y$, predice $y_{pred}$ a partir de $X$, y devuelve el porcentaje de acierto de $y_{pred}$ respecto a $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Clase `Node`\n",
    "Antes de implementar la clase principal `C45Classifier`, vamos a crear una clase `Node` que codifique la información necesaria para cada uno de los nodos del árbol. Cuenta con las siguientes funciones:\n",
    "- `__init__(self):` Constructor. En él inicializamos las variables necesarias, explicadas en los comentarios del código.\n",
    "- `__str__(self):` Método que nos permite imprimir nuestros árboles.\n",
    "- `predict(self,x):` Método que nos permitirá hacer predicciones recursivamente hasta llegar a un nodo hoja. Cuando el `Node` es hoja devuelve el valor de su clase, y si no, tendrá que llamar a la función `predict(x)` del hijo que corresponda. \n",
    "\n",
    "## **<font color=\"#B30033\" size=6>TAREA: </font>** Método predict para variables continuas\n",
    "El método `predict` actualmente se proporciona adaptado a la predicción de variables discretas. Deberéis ampliarlo para que funcione cuando la variable del nodo es continua."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Node:\n",
    "    def __init__(self):\n",
    "        # Indica si el nodo es una hoja, o no\n",
    "        self.is_leaf = False\n",
    "\n",
    "        # Atributos relacionados con la variable que representa el nodo\n",
    "        self.is_num = True      # Indica si la variable es numérica (True) o categórica (False)\n",
    "        self.cat_dict = None    # Diccionario para variables categóricas con formato {valor: indice}\n",
    "        \n",
    "        # Atributos cuando el objeto es una raíz\n",
    "        self.var = None         # Nombre de la variable de corte\n",
    "        self.var_index = -1     # Índice de la variable de corte\n",
    "        self.cut_value = 0      # Valor de la variable de corte, en caso de ser numérica\n",
    "        self.children = []      # Lista de hijos\n",
    "\n",
    "        # Atributos cuando el objeto es una hoja\n",
    "        self.class_value = -1       # Valor de la clase si el nodo es hoja\n",
    "        self.class_count = (0,0)    # Tupla con el formato (casos con valor class_value, casos totales en la hoja)\n",
    "\n",
    "        # Profundidad del nodo\n",
    "        self.depth = -1\n",
    "\n",
    "    def __str__(self):\n",
    "        output = ''\n",
    "        if(self.is_leaf):\n",
    "            output += 'Class value: ' + str(self.class_value) + '\\tCounts: ' + str(self.class_count)\n",
    "        else:\n",
    "            output += 'Feature '+ str(self.var)\n",
    "            for i in range(len(self.children)):\n",
    "                output += '\\n'+'\\t'*(self.depth+1)+str(self.cut_value)+': '+str(self.children[i]) \n",
    "            \n",
    "        return output\n",
    "    \n",
    "    # Esta función nos servirá para hacer predicciones recursivamente hasta llegar a un nodo hoja. Debe ser completada\n",
    "    def predict(self,x):\n",
    "        if self.is_leaf:\n",
    "            return self.class_value\n",
    "        else:\n",
    "            if self.is_num:\n",
    "                pass # TODO: Completar aquí\n",
    "            else:\n",
    "                pass # TODO: Completar aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Clase `C45Classifier`\n",
    "Esta será la clase principal, que representará nuestro clasificador C4.5. Los argumentos que recibirá serán los siguientes:\n",
    "* `vars`, `disc`, `cont`: 3 listas. Nombres de las variables con el mismo orden con el que aparecen en $X$, y de ellas, cuáles son discretas y cuales son continuas. No sería estrictamente necesario, pero simplificará bastante el desarrollo de la práctica.\n",
    "* `max_depth`: Profundidad máxima del árbol. Si no se especifica, será 2.\n",
    "* `criterion`: Criterio de partición. Puede tomar los valores `classification_error`, `entropy` y `gini`. Si no se especifica, será 'entropy'.\n",
    "* `prune`: Booleano. Si es `True`, se podará el árbol. Si no se especifica, será `False`.\n",
    "\n",
    "\n",
    "## **<font color=\"#B30033\" size=6>TAREA: </font>** Implementación del índice GINI y la entropía condicional\n",
    "\n",
    "\n",
    "## **<font color=\"#B30033\" size=6>TAREA: </font>** Uso de variables continuas\n",
    "\n",
    "\n",
    "## **<font color=\"#B30033\" size=6>TAREA: </font>** Poda del árbol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from collections import Counter\n",
    "\n",
    "class C45Classifier(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    # Constructor de la clase, aquí se definen e inicializan las variables de la clase.\n",
    "    def __init__(self, vars, disc, cont, max_depth=2, criterion='classification_error', prune=False):\n",
    "        self.max_depth = max_depth\n",
    "        self.criterion = criterion\n",
    "        self.prune = prune\n",
    "\n",
    "        self.vars = vars\n",
    "        self.disc = disc\n",
    "        self.cont = cont\n",
    "\n",
    "        # Diccionario que nos permitirá convertir el nombre de la variable en su índice.\n",
    "        self.features_dict = {feat: i for i, feat in enumerate(self.vars)}\n",
    "\n",
    "        # Raíz del árbol\n",
    "        self.tree = Node()   \n",
    "\n",
    "\n",
    "    # Función para entrenar el modelo.\n",
    "    def fit(self, X, y):\n",
    "        # Llamada a la función recursiva que aprende el árbol.\n",
    "        self._partial_fit(X, y, self.tree, 0, set([]))\n",
    "\n",
    "        if self.prune:\n",
    "            self._prune_tree()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "\n",
    "    # Función para hacer predicciones.\n",
    "    def predict(self, X):\n",
    "        return np.array([self.tree.predict(x) for x in X])\n",
    "    \n",
    "\n",
    "    # Función recursiva que busca la variable y corte que maximiza la ganancia de información.\n",
    "    # - Las variables continuas se tratan con un corte binario, lo que quiere decir que pueden ser usadas multiples veces. \n",
    "    # - Las variables discretas ramifican tantas veces como valores tengan, asi que solo pueden ser usadas una vez por camino, \n",
    "    #   debiendo almacenarlas en el conjunto `borradas`. \n",
    "    def _partial_fit(self, X, y, current_tree, current_depth, borradas):\n",
    "        def _make_leaf():\n",
    "            current_tree.is_leaf = True\n",
    "            counts = Counter(y)\n",
    "            max_value = counts.most_common(1) # most_common(1) devuelve una lista con el elemento más común y su frecuencia.\n",
    "            current_tree.class_value = max_value[0][0]\n",
    "            current_tree.class_count = (max_value[0][1], len(y))\n",
    "            return\n",
    "        \n",
    "        # Antes de nada, si hemos alcanzado la profundidad máxima, el nodo se convierte en hoja.\n",
    "        if current_depth >= self.max_depth:\n",
    "            _make_leaf()\n",
    "            return\n",
    "\n",
    "        # Primero obtenemos el mejor punto de corte para el nodo actual dependiendo del criterio.\n",
    "        best_var, cut_value, is_num = self._split(X, y, borradas, self.criterion)\n",
    "\n",
    "        # Si no hay ninguna partición que mejore la actual, el nodo se convierte en hoja.\n",
    "        if best_var is None:\n",
    "            _make_leaf()\n",
    "            return\n",
    "    \n",
    "        # Antes de llamar a la función recursiva, hay que actualizar los valores del árbol.\n",
    "        borradas_copy = borradas.copy()\n",
    "        if not is_num:    # Solo borramos las variables categóricas ya que estarán totalmente particionadas.\n",
    "            borradas_copy.add(best_var)\n",
    "            current_tree.is_num = False\n",
    "\n",
    "        current_tree.is_leaf = False\n",
    "        current_tree.depth = current_depth\n",
    "        current_tree.var = best_var\n",
    "        current_tree.var_index = self.features_dict[best_var]\n",
    "\n",
    "        # Finalmente, se hace la llamada recursiva en función de si es numérica o categórica.\n",
    "        if is_num:\n",
    "            pass # TODO: Completar aquí.\n",
    "        \n",
    "        else:\n",
    "            pass # TODO: Completar aquí.\n",
    "        \n",
    "        return\n",
    "\n",
    "\n",
    "    # Cálculo del mejor punto de corte en función de: Error de clasificación.\n",
    "    def _split(self, X, y, borradas, criterion='classification_error'):\n",
    "        # Error actual (sin partición)\n",
    "        error_best = self._compute_split_criterion(y, criterion)\n",
    "\n",
    "        best_var = None\n",
    "        is_num = True\n",
    "        cut_value = None    # Para variables categóricas no hay valor de corte (devolvemos None).\n",
    "        \n",
    "        for var in self.vars:\n",
    "            index = self.features_dict[var]\n",
    "            \n",
    "            if var in self.disc:\n",
    "                pass # TODO: Completar aquí.\n",
    "                \n",
    "            elif var in self.cont:\n",
    "                pass # TODO: Completar aquí.\n",
    "\n",
    "            # Si conseguimos un error de 0 (óptimo), terminamos\n",
    "            if error_best == 0:\n",
    "                break\n",
    "\n",
    "        return best_var, cut_value, is_num\n",
    "    \n",
    "    # TODO: Cálculo del mejor punto de corte en función de: Error de clasificación; Entropía; Índice Gini.\n",
    "    def _compute_split_criterion(self, y, criterion='classification_error'):\n",
    "        # TODO: Completar aquí si tenéis código común a los tres criterios.\n",
    "\n",
    "        if criterion == 'classification_error':\n",
    "            pass # TODO: Completar aquí.\n",
    "        elif criterion == 'entropy':\n",
    "            pass # TODO: Completar aquí.\n",
    "        elif criterion == 'gini':\n",
    "            pass # TODO: Completar aquí.\n",
    "        else:\n",
    "            raise ValueError('Criterio no válido.')\n",
    "\n",
    "    \n",
    "    # TODO: Completar esta función para realizar la poda del modelo.\n",
    "    def _prune_tree(self):\n",
    "        pass\n",
    "\n",
    "    # Función para imprimir el modelo.\n",
    "    def __str__(self):\n",
    "        return str(self.tree)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# 5. Pruebas y estudio del algoritmo implementado\n",
    "\n",
    "Finalmente, se deberán realizar pruebas con el clasificador para verificar su funcionamiento. A continuación, se incluyen algunos ejemplos de ejecución. Podéis incluir estos ejemplos en vuestra entrega, pero deberéis añadir más para demostrar que todas las partes de la práctica funcionan correctamente (variables continuas/discretas; error de clasificación/entropía/gini; con poda/sin poda, etc.). Además, se deberá razonar por qué los resultados son distintos de un caso a otro. \n",
    "\n",
    "Este apartado es más \"libre\", por lo que podéis hacer todas las pruebas y comparaciones que consideréis relevantes. Por ejemplo, podéis comparar vuestro algoritmo con los valores obtenidos por los árboles de `scikit-learn`, medir tiempos de ejecución... Además, si habéis incluido alguna característica opcional o distintiva de vuestro algoritmo, también debéis explicarla en este apartado.\n",
    "\n",
    "\n",
    "### IMPORTANTE\n",
    "\n",
    "**Se deberá mantener la eficiencia del clasificador. Esto significa que el tiempo de entrenamiento del árbol utilizando variables discretas o ambos tipos de variables debe ser similar. Obviamente, será mayor al incluir variables continuas en comparación con entrenar solo con las discretas (ya que solo se pueden particionar una vez), pero debe mantenerse dentro de un orden de magnitud similar.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables discretas, profundidad máxima 3, criterion='classification_error', sin poda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol = C45Classifier(attributes, disc_atts, [], max_depth=3, criterion='classification_error', prune=False)\n",
    "arbol.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Error en train: \", arbol.score(X,y))\n",
    "print(\"Error en test:  \", arbol.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables discretas, profundidad máxima 10, criterion='classification_error', sin poda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Al no estar implementado todavía el tratamiento de variables continuas, da igual que se especifiquen o no.\n",
    "arbol = C45Classifier(attributes, disc_atts, [], max_depth=10, criterion='classification_error', prune=False)\n",
    "arbol.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Error en train: \", arbol.score(X,y))\n",
    "print(\"Error en test:  \", arbol.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables discretas y continuas, profundidad máxima 2, criterion='classification_error', sin poda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Al no estar implementado todavía el tratamiento de variables continuas, da igual que se especifiquen o no.\n",
    "arbol = C45Classifier(attributes, disc_atts, cont_atts, max_depth=2, criterion='classification_error', prune=False)\n",
    "arbol.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Error en train: \", arbol.score(X,y))\n",
    "print(\"Error en test:  \", arbol.score(X_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
